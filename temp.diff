diff --git a/big.diff b/big.diff
deleted file mode 100644
index a528b4f..0000000
--- a/big.diff
+++ /dev/null
@@ -1,378 +0,0 @@
-diff --git a/src/docFillerCore/engines/consensusEngine.ts b/src/docFillerCore/engines/consensusEngine.ts
-index 18fd0a3..1117c30 100644
---- a/src/docFillerCore/engines/consensusEngine.ts
-+++ b/src/docFillerCore/engines/consensusEngine.ts
-@@ -50,7 +50,9 @@ class ConsensusEngine {
-     fieldType: QType,
-   ): Promise<LLMResponse | null> {
-     const responses = [];
--    for (const [llmType, weight] of ConsensusEngine.llmWeights.entries()) {
-+    const entries = Array.from(ConsensusEngine.llmWeights.entries());
-+    for (let i = 0; i < entries.length; i++) {
-+      const [llmType, weight] = entries[i] as [LLMEngineType, number];
-       try {
-         const llm = LLMEngine.getInstance(llmType);
-         const response = await llm.getResponse(promptString, fieldType);
-@@ -67,9 +69,10 @@ class ConsensusEngine {
-               value: response ?? {},
-             });
-           }
-+        } else {
-+          console.log(response);
-         }
-       } catch (error) {
--        // Handle the error here
-         console.error(error);
-         continue;
-       }
-diff --git a/src/docFillerCore/engines/gptEngine.ts b/src/docFillerCore/engines/gptEngine.ts
-index 0c6db9f..f6d1e8b 100644
---- a/src/docFillerCore/engines/gptEngine.ts
-+++ b/src/docFillerCore/engines/gptEngine.ts
-@@ -1,3 +1,8 @@
-+/* eslint-disable @typescript-eslint/no-unsafe-member-access */
-+/* eslint-disable @typescript-eslint/no-unsafe-return */
-+/* eslint-disable @typescript-eslint/no-unsafe-assignment */
-+/* eslint-disable no-console */
-+/* eslint-disable @typescript-eslint/no-explicit-any */
- import process from 'process';
- 
- import { Ollama } from '@langchain/ollama';
-@@ -22,137 +27,110 @@ import {
-   getAnthropicApiKey,
- } from '@utils/getProperties';
- 
-+type LLMInstance =
-+  | ChatOpenAI
-+  | Ollama
-+  | ChatGoogleGenerativeAI
-+  | ChatAnthropic
-+  | ChatMistralAI;
-+
- export class LLMEngine {
-   private static instance: LLMEngine;
-   private static engine: LLMEngineType;
--  private static openai: ChatOpenAI;
--  private static ollama: Ollama;
--  private static gemini: ChatGoogleGenerativeAI;
--  private static antropic: ChatAnthropic;
--  private static mistral: ChatMistralAI;
--
--  private chatGptApiKey: string | undefined;
--  private geminiApiKey: string | undefined;
--  private mistralApiKey: string | undefined;
--  private anthropicApiKey: string | undefined;
-+  private static instances: Record<LLMEngineType, LLMInstance | undefined> = {
-+    [LLMEngineType.ChatGPT]: undefined,
-+    [LLMEngineType.Gemini]: undefined,
-+    [LLMEngineType.Ollama]: undefined,
-+    [LLMEngineType.Mistral]: undefined,
-+    [LLMEngineType.Anthropic]: undefined,
-+  };
-+
-+  private static apiKeys: Record<string, string | undefined> = {
-+    chatGptApiKey: undefined,
-+    geminiApiKey: undefined,
-+    mistralApiKey: undefined,
-+    anthropicApiKey: undefined,
-+  };
- 
-   private constructor(engine: LLMEngineType) {
-     LLMEngine.engine = engine;
- 
--    this.fetchApiKeys()
-+    LLMEngine.fetchApiKeys()
-       .then(() => {
--        console.log('API keys fetched:', {
--          chatGptApiKey: this.chatGptApiKey,
--          geminiApiKey: this.geminiApiKey,
--          mistralApiKey: this.mistralApiKey,
--          anthropicApiKey: this.anthropicApiKey,
--        });
-+        console.log('API keys fetched:', LLMEngine.apiKeys);
- 
--        LLMEngine.instantiateEngine(LLMEngine.engine);
-+        try {
-+          LLMEngine.instantiateEngine(LLMEngine.engine);
-+        } catch (error) {
-+          console.error('Error instantiating engine:', error);
-+        }
-       })
-       .catch((error) => {
-         console.error('Error fetching API keys:', error);
-       });
-   }
- 
--  private async fetchApiKeys(): Promise<void> {
--    this.chatGptApiKey = await getChatGptApiKey();
--    this.geminiApiKey = await getGeminiApiKey();
--    this.mistralApiKey = await getMistralApiKey();
--    this.anthropicApiKey = await getAnthropicApiKey();
-+  private static async fetchApiKeys(): Promise<void> {
-+    LLMEngine.apiKeys.chatGptApiKey = await getChatGptApiKey();
-+    LLMEngine.apiKeys.geminiApiKey = await getGeminiApiKey();
-+    LLMEngine.apiKeys.mistralApiKey = await getMistralApiKey();
-+    LLMEngine.apiKeys.anthropicApiKey = await getAnthropicApiKey();
-   }
- 
--  public static instantiateEngine(
--    engine: LLMEngineType,
--  ):
--    | ChatOpenAI
--    | Ollama
--    | ChatGoogleGenerativeAI
--    | ChatAnthropic
--    | ChatMistralAI {
-+  public static instantiateEngine(engine: LLMEngineType): LLMInstance {
-+    if (LLMEngine.instances[engine]) {
-+      return LLMEngine.instances[engine];
-+    }
-+
-     switch (engine) {
--      case LLMEngineType.ChatGPT: {
--        if (LLMEngine.openai) {
--          return LLMEngine.openai;
--        }
--        if (!LLMEngine.instance.chatGptApiKey) {
--          throw new Error('ChatGPT API key is not defined');
--        }
--        LLMEngine.openai = new ChatOpenAI({
-+      case LLMEngineType.ChatGPT:
-+        LLMEngine.instances[engine] = new ChatOpenAI({
-           model: 'gpt-4',
--          apiKey: LLMEngine.instance.chatGptApiKey,
-+          apiKey: LLMEngine.apiKeys.chatGptApiKey as string,
-         });
--        return LLMEngine.openai;
--      }
--
--      case LLMEngineType.Gemini: {
--        if (LLMEngine.gemini) {
--          return LLMEngine.gemini;
--        }
--        if (!LLMEngine.instance.geminiApiKey) {
--          throw new Error('Gemini API key is not defined');
--        }
--        LLMEngine.gemini = new ChatGoogleGenerativeAI({
-+        break;
-+      case LLMEngineType.Gemini:
-+        LLMEngine.instances[engine] = new ChatGoogleGenerativeAI({
-           model: 'gemini-pro',
-           temperature: 0,
-           maxRetries: 2,
--          apiKey: LLMEngine.instance.geminiApiKey,
-+          apiKey: LLMEngine.apiKeys.geminiApiKey as string,
-         });
--        return LLMEngine.gemini;
--      }
--
--      case LLMEngineType.Ollama: {
--        if (LLMEngine.ollama) {
--          return LLMEngine.ollama;
--        }
--        LLMEngine.ollama = new Ollama({
-+        break;
-+      case LLMEngineType.Ollama:
-+        LLMEngine.instances[engine] = new Ollama({
-           model: 'gemma2:2b',
-           temperature: 0,
-           maxRetries: 2,
-         });
--        return LLMEngine.ollama;
--      }
--
--      case LLMEngineType.Mistral: {
--        if (LLMEngine.mistral) {
--          return LLMEngine.mistral;
--        }
--        if (!LLMEngine.instance.mistralApiKey) {
--          throw new Error('Mistral API key is not defined');
--        }
--        LLMEngine.mistral = new ChatMistralAI({
-+        break;
-+      case LLMEngineType.Mistral:
-+        LLMEngine.instances[engine] = new ChatMistralAI({
-           model: 'mistral-large-latest',
-           temperature: 0,
-           maxRetries: 2,
--          apiKey: LLMEngine.instance.mistralApiKey,
-+          apiKey: LLMEngine.apiKeys.mistralApiKey as string,
-         });
--        return LLMEngine.mistral;
--      }
--
--      case LLMEngineType.Anthropic: {
--        if (LLMEngine.antropic) {
--          return LLMEngine.antropic;
--        }
--        if (!LLMEngine.instance.anthropicApiKey) {
--          throw new Error('Anthropic API key is not defined');
--        }
--        LLMEngine.antropic = new ChatAnthropic({
-+        break;
-+      case LLMEngineType.Anthropic:
-+        LLMEngine.instances[engine] = new ChatAnthropic({
-           model: 'claude-3-haiku-20240307',
-           temperature: 0,
-           maxRetries: 2,
--          apiKey: LLMEngine.instance.anthropicApiKey,
-+          apiKey: LLMEngine.apiKeys.anthropicApiKey as string,
-         });
--        return LLMEngine.antropic;
--      }
-+        break;
-     }
-+
-+    return LLMEngine.instances[engine];
-   }
- 
-   public static getInstance(engine: LLMEngineType): LLMEngine {
--    if (LLMEngine.instance && LLMEngine.engine === engine) {
--      return LLMEngine.instance;
-+    if (!LLMEngine.instance) {
-+      LLMEngine.instance = new LLMEngine(engine);
-+    } else {
-+      LLMEngine.instantiateEngine(engine);
-     }
--
--    LLMEngine.instance = new LLMEngine(engine);
-     return LLMEngine.instance;
-   }
- 
-@@ -180,45 +158,15 @@ export class LLMEngine {
-     promptText: string,
-     questionType: QType,
-   ): Promise<LLMResponse | null> {
-+    console.log(promptText);
-+    console.log(questionType);
-     if (!promptText) {
-       return null;
-     }
-     try {
--      let response = null;
-       const parser = LLMEngine.getParser(questionType);
--      let modelInstance;
--      switch (LLMEngine.engine) {
--        case LLMEngineType.ChatGPT: {
--          if (LLMEngine.openai) {
--            modelInstance = LLMEngine.openai;
--          }
--          break;
--        }
--        case LLMEngineType.Gemini: {
--          if (LLMEngine.gemini) {
--            modelInstance = LLMEngine.gemini;
--          }
--          break;
--        }
--        case LLMEngineType.Ollama: {
--          if (LLMEngine.ollama) {
--            modelInstance = LLMEngine.ollama;
--          }
--          break;
--        }
--        case LLMEngineType.Mistral: {
--          if (LLMEngine.mistral) {
--            modelInstance = LLMEngine.mistral;
--          }
--          break;
--        }
--        case LLMEngineType.Anthropic: {
--          if (LLMEngine.antropic) {
--            modelInstance = LLMEngine.antropic;
--          }
--          break;
--        }
--      }
-+      const modelInstance = LLMEngine.instances[LLMEngine.engine];
-+
-       if (modelInstance) {
-         const chain = RunnableSequence.from([
-           PromptTemplate.fromTemplate(
-@@ -228,7 +176,7 @@ export class LLMEngine {
-           parser,
-         ]);
- 
--        response = await chain.invoke({
-+        const response = await chain.invoke({
-           question: promptText,
-           format_instructions: parser.getFormatInstructions(),
-         });
-@@ -237,8 +185,8 @@ export class LLMEngine {
-       return null;
-     } catch (error) {
-       console.error('Error getting response:', error);
-+      return null;
-     }
--    return null;
-   }
- 
-   private patchResponse(response: any, questionType: QType): LLMResponse {
-@@ -280,6 +228,7 @@ export class LLMEngine {
-   ): StructuredOutputParser<any> | DatetimeOutputParser | StringOutputParser {
-     switch (questionType) {
-       case QType.TEXT:
-+      case QType.PARAGRAPH:
-         return new StringOutputParser();
-       case QType.TEXT_EMAIL:
-         return StructuredOutputParser.fromNamesAndDescriptions({
-@@ -290,7 +239,6 @@ export class LLMEngine {
-         return StructuredOutputParser.fromNamesAndDescriptions({
-           answer: 'Give Correct Url corresponding to given question',
-         });
--
-       case QType.DATE:
-       case QType.TIME:
-       case QType.DATE_AND_TIME:
-@@ -301,7 +249,6 @@ export class LLMEngine {
-       case QType.TIME_WITH_MERIDIEM:
-       case QType.DURATION:
-         return new DatetimeOutputParser();
--
-       case QType.LINEAR_SCALE:
-         return StructuredOutputParser.fromZodSchema(
-           z.object({
-@@ -312,14 +259,10 @@ export class LLMEngine {
-               ),
-           }),
-         );
--
-       case QType.DROPDOWN:
-         return StructuredOutputParser.fromNamesAndDescriptions({
-           answer: "answer to the user's question",
-         });
--      case QType.PARAGRAPH:
--        return new StringOutputParser();
--
-       case QType.CHECKBOX_GRID: {
-         const checkboxGridColSchema = z.object({
-           data: z
-@@ -348,7 +291,6 @@ export class LLMEngine {
- 
-         return StructuredOutputParser.fromZodSchema(checkboxGridArraySchema);
-       }
--
-       case QType.MULTIPLE_CHOICE_GRID: {
-         const multipleChoiceGridRowSchema = z.object({
-           row: z
-@@ -373,7 +315,6 @@ export class LLMEngine {
-           multipleChoiceGridArraySchema,
-         );
-       }
--
-       case QType.MULTIPLE_CHOICE:
-       case QType.MULTIPLE_CHOICE_WITH_OTHER:
-       case QType.MULTI_CORRECT:
-diff --git a/src/utils/settings.ts b/src/utils/settings.ts
-index 12dc087..09aaebc 100644
---- a/src/utils/settings.ts
-+++ b/src/utils/settings.ts
-@@ -50,7 +50,7 @@ class Settings {
- 
-   public async getEnableConsensus(): Promise<boolean> {
-     if (!this.enableConsensus) {
--      this.enableConsensus = (await getEnableConsensus()) || true;
-+      this.enableConsensus = (await getEnableConsensus()) || false;
-     }
-     return this.enableConsensus;
-   }
diff --git a/public/src/options/index.html b/public/src/options/index.html
index 71ac487..03c0b63 100644
--- a/public/src/options/index.html
+++ b/public/src/options/index.html
@@ -15,39 +15,14 @@
             <label for="sleepDuration">Sleep Duration (ms):</label>
             <input type="number" id="sleepDuration" name="sleepDuration" min="100" step="100" value="2000">
         </div>
-        <div class="form-group">
-
-            <label for="chatGptApiKey">ChatGPT API Key:</label>
-          
-            <input type="text" id="chatGptApiKey" name="chatGptApiKey">
-          
-          </div>
-          
-          <div class="form-group">
-          
-            <label for="geminiApiKey">Gemini API Key:</label>
-          
-            <input type="text" id="geminiApiKey" name="geminiApiKey"  value="thsiisthekey">
-          
-          </div>
-          
-          <div class="form-group">
-          
-            <label for="text">Mistral API Key:</label>
-          
-            <input type="password" id="mistralApiKey" name="mistralApiKey">
-          
-          </div>
-          
-          <div class="form-group">
-          
-            <label for="text">Anthropic API Key:</label>
-          
-            <input type="password" id="anthropicApiKey" name="anthropicApiKey">
-          
-          </div>
 
         <div class="form-group">
+            <label for="enableConsensus">Enable Consensus:</label>
+            <input type="checkbox" id="enableConsensus" name="enableConsensus">
+        </div>
+
+        <!-- Single Model API Key and Selection (only visible if consensus is off) -->
+        <div id="singleModelOptions" class="form-group">
             <label for="llmModel">LLM Model:</label>
             <select id="llmModel" name="llmModel">
                 <option value="Gemini">Gemini</option>
@@ -56,34 +31,42 @@
                 <option value="Mistral">Mistral</option>
                 <option value="Anthropic">Anthropic</option>
             </select>
+            <label for="singleApiKey">API Key:</label>
+            <input type="text" id="singleApiKey" name="singleApiKey">
         </div>
 
-        <div class="form-group">
-            <label for="enableConsensus">Enable Consensus:</label>
-            <input type="checkbox" id="enableConsensus" name="enableConsensus">
-        </div>
-
+        <!-- Consensus Mode Weights and API Keys (only visible if consensus is on) -->
         <div id="consensusWeights" class="hidden">
             <div class="form-group">
+                <label for="weightChatGPT">ChatGPT API Key:</label>
+                <input type="text" id="chatGptApiKey" name="chatGptApiKey">
                 <label for="weightChatGPT">ChatGPT Weight:</label>
                 <input type="number" id="weightChatGPT" name="weightChatGPT" min="0" max="1" step="0.01" value="0.42">
             </div>
             <div class="form-group">
+                <label for="geminiApiKey">Gemini API Key:</label>
+                <input type="text" id="geminiApiKey" name="geminiApiKey">
                 <label for="weightGemini">Gemini Weight:</label>
                 <input type="number" id="weightGemini" name="weightGemini" min="0" max="1" step="0.01" value="0.42">
             </div>
             <div class="form-group">
+                <label for="ollamaApiKey">Ollama API Key:</label>
+                <input type="text" id="ollamaApiKey" name="ollamaApiKey">
                 <label for="weightOllama">Ollama Weight:</label>
                 <input type="number" id="weightOllama" name="weightOllama" min="0" max="1" step="0.01" value="0.16">
             </div>
             <div class="form-group">
+                <label for="mistralApiKey">Mistral API Key:</label>
+                <input type="text" id="mistralApiKey" name="mistralApiKey">
                 <label for="weightMistral">Mistral Weight:</label>
                 <input type="number" id="weightMistral" name="weightMistral" min="0" max="1" step="0.01" value="0.16">
             </div>
-            <div class="form-group"></div>
-            <label for="weightAnthropic">Anthropic Weight:</label>
-            <input type="number" id="weightAnthropic" name="weightAnthropic" min="0" max="1" step="0.01" value="0.16">
-        </div>
+            <div class="form-group">
+                <label for="anthropicApiKey">Anthropic API Key:</label>
+                <input type="text" id="anthropicApiKey" name="anthropicApiKey">
+                <label for="weightAnthropic">Anthropic Weight:</label>
+                <input type="number" id="weightAnthropic" name="weightAnthropic" min="0" max="1" step="0.01" value="0.16">
+            </div>
         </div>
 
         <button type="button" id="saveButton">Save</button>
@@ -92,4 +75,4 @@
     <script src="options.js"></script>
 </body>
 
-</html>
\ No newline at end of file
+</html>
diff --git a/public/src/options/options.css b/public/src/options/options.css
index acec925..758c032 100644
--- a/public/src/options/options.css
+++ b/public/src/options/options.css
@@ -40,3 +40,64 @@ button {
 button:hover {
     background-color: #0056b3;
 }
+/* Add to existing options.css */
+.api-key {
+    display: none; /* Hide all API key inputs by default */
+}
+
+/* Show all API keys when consensus is enabled */
+#enableConsensus:checked ~ #apiKeysSection .api-key {
+    display: block;
+}
+
+/* Show only selected model's API key when consensus is disabled */
+#apiKeysSection .api-key.active {
+    display: block;
+}
+body {
+    font-family: Arial, sans-serif;
+    background-color: #f4f4f9;
+    color: #333;
+    margin: 20px;
+}
+
+h1 {
+    font-size: 1.8em;
+    color: #444;
+}
+
+.form-group {
+    margin-bottom: 1em;
+}
+
+label {
+    display: block;
+    font-weight: bold;
+    margin-bottom: 0.5em;
+}
+
+input[type="text"],
+input[type="number"],
+select {
+    width: 100%;
+    padding: 0.5em;
+    margin-bottom: 0.5em;
+    font-size: 1em;
+}
+
+button {
+    background-color: #4CAF50;
+    color: white;
+    padding: 0.6em 1.2em;
+    border: none;
+    cursor: pointer;
+    font-size: 1em;
+}
+
+button:hover {
+    background-color: #45a049;
+}
+
+.hidden {
+    display: none;
+}
diff --git a/src/docFillerCore/engines/gptEngine.ts b/src/docFillerCore/engines/gptEngine.ts
index f6d1e8b..6d2051e 100644
--- a/src/docFillerCore/engines/gptEngine.ts
+++ b/src/docFillerCore/engines/gptEngine.ts
@@ -26,6 +26,7 @@ import {
   getMistralApiKey,
   getAnthropicApiKey,
 } from '@utils/getProperties';
+import { LLM } from '@langchain/core/language_models/llms';
 
 type LLMInstance =
   | ChatOpenAI
@@ -75,21 +76,31 @@ export class LLMEngine {
     LLMEngine.apiKeys.geminiApiKey = await getGeminiApiKey();
     LLMEngine.apiKeys.mistralApiKey = await getMistralApiKey();
     LLMEngine.apiKeys.anthropicApiKey = await getAnthropicApiKey();
+    console.log(
+      LLMEngine.apiKeys.chatGptApiKey,
+      LLMEngine.apiKeys.geminiApiKey,
+    );
   }
 
   public static instantiateEngine(engine: LLMEngineType): LLMInstance {
-    if (LLMEngine.instances[engine]) {
-      return LLMEngine.instances[engine];
-    }
+    // if (LLMEngine.instances[engine]) {
+    //   return LLMEngine.instances[engine];
+    // }
 
+    // console.log(LLMEngineType);
+    // console.log("ENGINE",engine);
+    console.log(LLMEngine.apiKeys);
     switch (engine) {
       case LLMEngineType.ChatGPT:
+        console.log(LLMEngine.apiKeys);
         LLMEngine.instances[engine] = new ChatOpenAI({
           model: 'gpt-4',
           apiKey: LLMEngine.apiKeys.chatGptApiKey as string,
         });
         break;
       case LLMEngineType.Gemini:
+        console.log('gemini');
+        console.log(LLMEngine.apiKeys);
         LLMEngine.instances[engine] = new ChatGoogleGenerativeAI({
           model: 'gemini-pro',
           temperature: 0,
@@ -105,6 +116,7 @@ export class LLMEngine {
         });
         break;
       case LLMEngineType.Mistral:
+        console.log(LLMEngine.apiKeys);
         LLMEngine.instances[engine] = new ChatMistralAI({
           model: 'mistral-large-latest',
           temperature: 0,
@@ -113,6 +125,8 @@ export class LLMEngine {
         });
         break;
       case LLMEngineType.Anthropic:
+        console.log(LLMEngine.apiKeys);
+        console.log(LLMEngine.apiKeys.anthropicApiKey);
         LLMEngine.instances[engine] = new ChatAnthropic({
           model: 'claude-3-haiku-20240307',
           temperature: 0,
@@ -126,11 +140,11 @@ export class LLMEngine {
   }
 
   public static getInstance(engine: LLMEngineType): LLMEngine {
-    if (!LLMEngine.instance) {
-      LLMEngine.instance = new LLMEngine(engine);
-    } else {
-      LLMEngine.instantiateEngine(engine);
-    }
+    // if (!LLMEngine.instance) {
+    LLMEngine.instance = new LLMEngine(engine);
+    // } else {
+    // LLMEngine.instantiateEngine(engine);
+    // }
     return LLMEngine.instance;
   }
 
diff --git a/src/options/options.ts b/src/options/options.ts
index 3a786be..34d8562 100644
--- a/src/options/options.ts
+++ b/src/options/options.ts
@@ -1,7 +1,3 @@
-/* eslint-disable dot-notation */
-import { Settings } from '@utils/settings';
-import LLMEngineType, { getModelName } from '@utils/llmEngineTypes';
-
 document.addEventListener('DOMContentLoaded', () => {
   // Get elements from the DOM
   const sleepDurationInput = document.getElementById(
@@ -37,6 +33,9 @@ document.addEventListener('DOMContentLoaded', () => {
   const geminiApiKeyInput = document.getElementById(
     'geminiApiKey',
   ) as HTMLInputElement;
+  const ollamaApiKeyInput = document.getElementById(
+    'ollamaApiKey',
+  ) as HTMLInputElement;
   const mistralApiKeyInput = document.getElementById(
     'mistralApiKey',
   ) as HTMLInputElement;
@@ -44,6 +43,9 @@ document.addEventListener('DOMContentLoaded', () => {
     'anthropicApiKey',
   ) as HTMLInputElement;
   const saveButton = document.getElementById('saveButton') as HTMLButtonElement;
+  const singleApiKeyInput = document.getElementById(
+    'singleApiKey',
+  ) as HTMLInputElement;
 
   // Load saved options
   chrome.storage.sync.get(
@@ -54,47 +56,113 @@ document.addEventListener('DOMContentLoaded', () => {
       'llmWeights',
       'chatGptApiKey',
       'geminiApiKey',
+      'ollamaApiKey',
       'mistralApiKey',
       'anthropicApiKey',
     ],
     (items) => {
-      console.log('Loaded items:', items); // Debug log
-      sleepDurationInput.value = String(items['sleepDuration'] || 2000);
-      llmModelSelect.value =
-        String(items['llmModel']) ||
-        getModelName(Settings.getInstance().getDefaultLLMModel());
-      enableConsensusCheckbox.checked =
-        (items['enableConsensus'] as boolean) || false;
-      chatGptApiKeyInput.value = String(items['chatGptApiKey'] || '');
-      geminiApiKeyInput.value = String(items['geminiApiKey'] || '');
-      mistralApiKeyInput.value = String(items['mistralApiKey'] || '');
-      anthropicApiKeyInput.value = String(items['anthropicApiKey'] || '');
+      console.log('Loaded items from storage:', items);
+      sleepDurationInput.value = String(items.sleepDuration || 2000);
+      llmModelSelect.value = items.llmModel || 'Gemini';
+      enableConsensusCheckbox.checked = Boolean(items.enableConsensus);
+      chatGptApiKeyInput.value = items.chatGptApiKey || '';
+      geminiApiKeyInput.value = items.geminiApiKey || '';
+      ollamaApiKeyInput.value = items.ollamaApiKey || '';
+      mistralApiKeyInput.value = items.mistralApiKey || '';
+      anthropicApiKeyInput.value = items.anthropicApiKey || '';
 
-      if (items['enableConsensus']) {
-        consensusWeightsDiv.classList.remove('hidden');
-        const weights =
-          (items['llmWeights'] as Record<LLMEngineType, number>) || {};
-        weightChatGPTInput.value = String(
-          weights[LLMEngineType.ChatGPT] || 0.42,
-        );
-        weightGeminiInput.value = String(weights[LLMEngineType.Gemini] || 0.32);
-        weightOllamaInput.value = String(weights[LLMEngineType.Ollama] || 0.16);
-        weightMistralInput.value = String(
-          weights[LLMEngineType.Mistral] || 0.21,
-        );
-        weightAnthropicInput.value = String(
-          weights[LLMEngineType.Anthropic] || 0.31,
-        );
-      } else {
-        consensusWeightsDiv.classList.add('hidden');
-      }
+      // Show or hide elements based on consensus setting
+      toggleConsensusOptions(enableConsensusCheckbox.checked);
+      updateSingleApiKeyInput();
     },
   );
 
+  // Toggle visibility of elements based on consensus state
+  const toggleConsensusOptions = (enableConsensus: boolean) => {
+    console.log(`Toggling consensus options: ${enableConsensus}`);
+    if (enableConsensus) {
+      consensusWeightsDiv.classList.remove('hidden');
+      llmModelSelect.classList.add('hidden');
+      singleApiKeyInput.classList.add('hidden');
+    } else {
+      consensusWeightsDiv.classList.add('hidden');
+      llmModelSelect.classList.remove('hidden');
+      singleApiKeyInput.classList.remove('hidden');
+    }
+  };
+
+  // Update single API key input based on selected model
+  const updateSingleApiKeyInput = () => {
+    const selectedModel = llmModelSelect.value;
+    let apiKeyValue = '';
+
+    switch (selectedModel) {
+      case 'ChatGPT':
+        apiKeyValue = chatGptApiKeyInput.value;
+        break;
+      case 'Gemini':
+        apiKeyValue = geminiApiKeyInput.value;
+        break;
+      case 'Ollama':
+        console.log('Ollama model selected: no API key required');
+        apiKeyValue = '';
+        break;
+      case 'Mistral':
+        apiKeyValue = mistralApiKeyInput.value;
+        break;
+      case 'Anthropic':
+        apiKeyValue = anthropicApiKeyInput.value;
+        break;
+      default:
+        console.warn('Unknown model selected:', selectedModel);
+        break;
+    }
+
+    singleApiKeyInput.value = apiKeyValue;
+    console.log(`API key for ${selectedModel}:`, apiKeyValue);
+  };
+
+  // Save the API key to the corresponding model input when changed
+  singleApiKeyInput.addEventListener('input', () => {
+    const selectedModel = llmModelSelect.value;
+    const apiKeyValue = singleApiKeyInput.value;
+
+    switch (selectedModel) {
+      case 'ChatGPT':
+        chatGptApiKeyInput.value = apiKeyValue;
+        break;
+      case 'Gemini':
+        geminiApiKeyInput.value = apiKeyValue;
+        break;
+      case 'Ollama':
+        console.log(
+          "Ignoring input for Ollama model as it doesn't require an API key",
+        );
+        break;
+      case 'Mistral':
+        mistralApiKeyInput.value = apiKeyValue;
+        break;
+      case 'Anthropic':
+        anthropicApiKeyInput.value = apiKeyValue;
+        break;
+      default:
+        console.warn('Unknown model selected:', selectedModel);
+        break;
+    }
+    console.log(`Updated API key for ${selectedModel}:`, apiKeyValue);
+  });
+
   // Handle checkbox change
   enableConsensusCheckbox.addEventListener('change', (e: Event) => {
     const target = e.target as HTMLInputElement;
-    consensusWeightsDiv.classList.toggle('hidden', !target.checked);
+    console.log(`Enable consensus changed to: ${target.checked}`);
+    toggleConsensusOptions(target.checked);
+  });
+
+  // Handle model selection change to update API key input
+  llmModelSelect.addEventListener('change', () => {
+    console.log('Model selection changed to:', llmModelSelect.value);
+    updateSingleApiKeyInput();
   });
 
   // Save options
@@ -104,6 +172,7 @@ document.addEventListener('DOMContentLoaded', () => {
     const enableConsensus = enableConsensusCheckbox.checked;
     const chatGptApiKey = chatGptApiKeyInput.value;
     const geminiApiKey = geminiApiKeyInput.value;
+    const ollamaApiKey = ollamaApiKeyInput.value;
     const mistralApiKey = mistralApiKeyInput.value;
     const anthropicApiKey = anthropicApiKeyInput.value;
     const llmWeights: Record<string, number> = enableConsensus
@@ -116,9 +185,20 @@ document.addEventListener('DOMContentLoaded', () => {
         }
       : {};
 
-    // Debug: Log the API key to the console
-    console.log('ChatGPT API Key:', chatGptApiKey);
-    console.log('GEMINI API Key:', geminiApiKey);
+    // Log the entire data object for debugging
+    console.log('Attempting to save options:', {
+      sleepDuration,
+      llmModel,
+      enableConsensus,
+      llmWeights,
+      apiKeys: {
+        ChatGPT: chatGptApiKey,
+        Gemini: geminiApiKey,
+        Ollama: ollamaApiKey, // This will be ignored if it's Ollama
+        Mistral: mistralApiKey,
+        Anthropic: anthropicApiKey,
+      },
+    });
 
     try {
       await new Promise<void>((resolve, reject) => {
@@ -130,6 +210,7 @@ document.addEventListener('DOMContentLoaded', () => {
             llmWeights,
             chatGptApiKey,
             geminiApiKey,
+            ollamaApiKey,
             mistralApiKey,
             anthropicApiKey,
           },
@@ -143,26 +224,7 @@ document.addEventListener('DOMContentLoaded', () => {
         );
       });
 
-      // Debug: Log after saving
       console.log('Options saved successfully.');
-
-      // Retrieve and log the saved items
-      chrome.storage.sync.get(
-        [
-          'sleepDuration',
-          'llmModel',
-          'enableConsensus',
-          'llmWeights',
-          'chatGptApiKey',
-          'geminiApiKey',
-          'mistralApiKey',
-          'anthropicApiKey',
-        ],
-        (items) => {
-          console.log('Retrieved items after save:', items);
-          alert('Options saved and retrieved successfully.');
-        },
-      );
     } catch (error) {
       console.error('Error saving options:', error);
       alert('Error saving options. Please try again.');
